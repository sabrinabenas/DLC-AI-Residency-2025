{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CEBRA es un método de machine learning que puede usarse para comprimir series temporales de una forma que revela estructuras ocultas en la variabilidad de los datos. Se destaca especialmente en datos conductuales y neuronales registrados de manera simultánea.\n",
        "\n",
        "Decodificación a partir de un embedding de CEBRA\n",
        "\n",
        "En este notebook mostramos cómo:\n",
        "\n",
        "- Decodificar etiquetas a partir de un embedding de CEBRA.\n",
        "\n",
        "- Evaluar y comparar el rendimiento de la decodificación en embeddings obtenidos bajo diferentes hipótesis.\n",
        "\n",
        "Esto se basa en lo presentado en *Schneider, Lee, Mathis.*\n",
        "\n",
        "[ref con datos](https://colab.research.google.com/github/AdaptiveMotorControlLab/CEBRA-demos/blob/main/Demo_hippocampus.ipynb)"
      ],
      "metadata": {
        "id": "GCKMr49H0pLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre 'cebra[datasets, integrations]'"
      ],
      "metadata": {
        "id": "k6P9hTcP0aS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib as jl\n",
        "import cebra.datasets\n",
        "from cebra import CEBRA\n",
        "\n",
        "from matplotlib.collections import LineCollection\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DNht_Q631Jpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cargar los datos"
      ],
      "metadata": {
        "id": "is1xmyWb1RV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## completar con un npy (por ejemplo)"
      ],
      "metadata": {
        "id": "JKjCwoms1Zyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oixnaTC2GqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## usamos CEBRA para encontrar el espacio de baja dimension de nuestros datos"
      ],
      "metadata": {
        "id": "KX0LHC9w2HTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Define the model\n",
        "max_iterations = 5000\n",
        "cebra_posdir3_model = CEBRA(model_architecture='offset10-model',\n",
        "                        batch_size=512,\n",
        "                        learning_rate=3e-4,\n",
        "                        temperature=1,\n",
        "                        output_dimension=3,\n",
        "                        max_iterations=max_iterations,\n",
        "                        distance='cosine',\n",
        "                        conditional='time_delta',\n",
        "                        device='cuda_if_available',\n",
        "                        verbose=True,\n",
        "                        time_offsets=10)"
      ],
      "metadata": {
        "id": "Zl7S3oX01SxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cebra.models\n",
        "print(cebra.models.get_options('offset*'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPl5WREBP-RT",
        "outputId": "f384ca22-e5e3-4f75-d20a-b98d922b39af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['offset10-model', 'offset10-model-mse', 'offset5-model', 'offset1-model-mse', 'offset1-model', 'offset1-model-v2', 'offset1-model-v3', 'offset1-model-v4', 'offset1-model-v5', 'offset40-model-4x-subsample', 'offset20-model-4x-subsample', 'offset4-model-2x-subsample', 'offset36-model', 'offset36-model-dropout', 'offset36-model-more-dropout']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Split data and labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "split_idx = int(0.8 * len(hippocampus_pos.neural)) #suggest: 5%-20% depending on your dataset size\n",
        "\n",
        "train_data = hippocampus_pos.neural[:split_idx]\n",
        "valid_data = hippocampus_pos.neural[split_idx:]\n",
        "\n",
        "train_continuous_label = hippocampus_pos.continuous_index.numpy()[:split_idx]\n",
        "valid_continuous_label = hippocampus_pos.continuous_index.numpy()[split_idx:]"
      ],
      "metadata": {
        "id": "rsjjGDDN1bfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamos el modelo --> recomendacion usar GPU la coalb\n",
        "cebra_posdir3_model.fit(train_data, train_continuous_label)"
      ],
      "metadata": {
        "id": "-teZD26Y1bbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# guardamos el modelo\n",
        "# 5. Save the model\n",
        "import os\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "tmp_file = Path(tempfile.gettempdir(), 'cebra.pt')\n",
        "cebra_posdir3_model.save(tmp_file)"
      ],
      "metadata": {
        "id": "qdCvbila1k67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. cargamos el modelo y calculamos el embedding\n",
        "cebra_posdir3_model = cebra.CEBRA.load(tmp_file)\n",
        "train_embedding = cebra_posdir3_model.transform(train_data)\n",
        "valid_embedding = cebra_posdir3_model.transform(valid_data)\n"
      ],
      "metadata": {
        "id": "EdPY06Yl1bZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizacion\n",
        "import cebra.integrations.plotly\n",
        "\n",
        "fig = cebra.integrations.plotly.plot_embedding_interactive(train_embedding,\n",
        "                                                           embedding_labels=train_continuous_label[:,0],\n",
        "                                                           title = \"CEBRA-Behavior Train\",\n",
        "                                                           markersize=2,\n",
        "                                                           cmap = \"rainbow\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Zs01W6bH1bTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra: decoding\n",
        "[Ref](https://cebra.ai/docs/demo_notebooks/Demo_decoding.html)"
      ],
      "metadata": {
        "id": "U4_bFCwqdos-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "# Define decoding function with kNN decoder. For a simple demo, we will use the fixed number of neighbors 36.\n",
        "def decoding_pos_dir(embedding_train, embedding_test, label_train, label_test):\n",
        "   pos_decoder = cebra.KNNDecoder(n_neighbors=100, metric=\"cosine\")\n",
        "\n",
        "   pos_decoder.fit(embedding_train, label_train)\n",
        "\n",
        "   pos_pred = pos_decoder.predict(embedding_test)\n",
        "   #print(pos_pred)\n",
        "\n",
        "   prediction = np.stack([pos_pred],axis = 1)\n",
        "   #print(prediction)\n",
        "   test_score = sklearn.metrics.r2_score(label_test, pos_pred)\n",
        "   pos_test_err = np.median(abs(pos_pred[:,0] - label_test[:, 0]))\n",
        "   pos_test_score = sklearn.metrics.r2_score(label_test[:, 0], pos_pred[:,0])\n",
        "\n",
        "   return prediction,test_score, pos_test_err, pos_test_score"
      ],
      "metadata": {
        "id": "MLYyvpHsfF9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}